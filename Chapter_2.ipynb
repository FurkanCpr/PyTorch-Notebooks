{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter - 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0v44aqQrokC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as t\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95lHAMz3rsxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])) # Some data types are not tensor so we convert them to tensor data type.\n",
        "# \"\" section is the place that you want to download the dataset to.\n",
        "\n",
        "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9liUZWr1gL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = t.utils.data.DataLoader(train, batch_size=10, shuffle=True) # batch_size = x meaning is pass x numbers of data passing to our model at the time.\n",
        "testset = t.utils.data.DataLoader(test, batch_size=10, shuffle=True) # shuffle is pass random number data (for MNIST) to our model in order to make model more generalized."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwkFJ_6ttznV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "95b22f25-1f33-489f-cbc5-819c1ddf0e5d"
      },
      "source": [
        "for data in trainset:\n",
        "  print(data)\n",
        "  print(data[0][0].shape)\n",
        "  break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 6, 1, 2, 2, 8, 8, 7, 6, 7])]\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMxKA9nowpau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8895ad16-652f-4a04-e33f-c4f74b5a940d"
      },
      "source": [
        "# data variable is a list containing image and it's label. Both of them is a tensor.\n",
        "x, y = data[0][0], data[1][0] # Image of 3, label of 3.\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfHhPSIOw0ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9a9e608d-e962-4993-bedd-41305a170d02"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Our data[0][0].shape is 1, 28, 28 so this is not an image shape so we will reshape ( view in pytorch ) this image to 28, 28 in order to show in matplotlib graph.\n",
        "plt.imshow(data[0][0].view(28, 28))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f90ec9fa7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQLjO0LgyGV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a668a2f9-926b-439e-eeb5-6546ffac9656"
      },
      "source": [
        "# We'll look and count our images for ensure our dataset is balanced.\n",
        "\n",
        "total = 0 \n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "for data in trainset:\n",
        "  xs, ys = data\n",
        "  for y in ys:\n",
        "    counter_dict[int(y)] += 1\n",
        "    total += 1\n",
        "\n",
        "print(counter_dict)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdvGa1lA1gzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3cce972d-4578-4059-ae37-19d2270c82f1"
      },
      "source": [
        "# Percentage of image classes\n",
        "\n",
        "for i in counter_dict:\n",
        "  print(f\"{i}: {counter_dict[i]/total*100} % \")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 9.8 % \n",
            "1: 11.35 % \n",
            "2: 10.32 % \n",
            "3: 10.100000000000001 % \n",
            "4: 9.82 % \n",
            "5: 8.92 % \n",
            "6: 9.58 % \n",
            "7: 10.280000000000001 % \n",
            "8: 9.74 % \n",
            "9: 10.09 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8sznCc17Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
